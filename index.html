<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI Camera Classifier</title>

  <!-- ‡πÇ‡∏´‡∏•‡∏î Teachable Machine ‡πÅ‡∏•‡∏∞ TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8.4/dist/teachablemachine-image.min.js"></script>

  <style>
    body { font-family: sans-serif; text-align: center; padding: 20px; }
    #webcam-container { margin: 20px auto; }
    #label-container > div { margin: 8px; font-size: 18px; }
    button { margin: 10px; padding: 10px 20px; }
  </style>
</head>
<body>
  <h1>üì∑ AI Camera Classifier</h1>
  <button onclick="init()">‚ñ∂Ô∏è Start</button>
  <button onclick="switchCamera()">üîÑ Switch to Front</button>

  <div id="webcam-container"></div>
  <div id="label-container"></div>

<script type="text/javascript">
  const URL = "./tm-my-image-model/";
  let model, webcam, labelContainer, maxPredictions;
  let currentFacingMode = "environment"; // ‚úÖ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á

  async function init() {
    try {
      if (webcam?.webcam?.srcObject) {
        webcam.webcam.srcObject.getTracks().forEach(track => track.stop());
        await webcam.stop();
      }

      const modelURL = URL + "model.json";
      const metadataURL = URL + "metadata.json";

      model = await tmImage.load(modelURL, metadataURL);
      maxPredictions = model.getTotalClasses();

      webcam = new tmImage.Webcam(300, 300, true, currentFacingMode);
      await webcam.setup();
      await webcam.play();
      window.requestAnimationFrame(loop);

      document.getElementById("webcam-container").innerHTML = "";
      document.getElementById("webcam-container").appendChild(webcam.canvas);

      labelContainer = document.getElementById("label-container");
      labelContainer.innerHTML = "";
      for (let i = 0; i < maxPredictions; i++) {
        labelContainer.appendChild(document.createElement("div"));
      }
    } catch (err) {
      alert("üìõ Error: " + err.message);
    }
  }

  async function loop() {
    webcam.update();
    await predict();
    window.requestAnimationFrame(loop);
  }

  async function predict() {
    const prediction = await model.predict(webcam.canvas);
    for (let i = 0; i < maxPredictions; i++) {
      const classPrediction =
        prediction[i].className + ": " + (prediction[i].probability * 100).toFixed(2) + "%";
      labelContainer.childNodes[i].innerHTML = classPrediction;
    }
  }

  function switchCamera() {
    // üîÅ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á
    currentFacingMode = currentFacingMode === "environment" ? "user" : "environment";
    document.querySelector("button:nth-of-type(2)").innerText =
      currentFacingMode === "environment" ? "üîÑ Switch to Front" : "üîÑ Switch to Back";
    init(); // ‡∏£‡∏µ‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á
  }
</script>

</body>
</html>
