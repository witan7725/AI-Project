<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI Camera Classifier</title>
  <!-- ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8.4/dist/teachablemachine-image.min.js"></script>
  <style>
    body { font-family: sans-serif; text-align: center; padding: 20px; }
    #webcam-container { margin: 20px auto; }
    #label-container > div { margin: 8px; font-size: 18px; }
    button { margin: 10px; padding: 10px 20px; }
  </style>
</head>
<body>
  <h1>üì∑ AI Camera Classifier</h1>
  <button onclick="startCamera()">‚ñ∂Ô∏è Start</button>
  <button onclick="toggleCamera()">üîÑ Switch Camera</button>
  <div id="webcam-container"></div>
  <div id="label-container"></div>

<script>
  const MODEL_PATH = "./tm-my-image-model/";
  let model, maxPredictions;
  let webcam; 
  let videoDevices = [];
  let currentIndex = 0;      // index ‡πÉ‡∏ô videoDevices
  let firstRun = true;

  // ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
  async function loadModel() {
    if (!model) {
      model = await tmImage.load(MODEL_PATH + "model.json", MODEL_PATH + "metadata.json");
      maxPredictions = model.getTotalClasses();
    }
  }

  // ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡πâ‡∏≠‡∏á videoinput
  async function enumerateVideoDevices() {
    const all = await navigator.mediaDevices.enumerateDevices();
    videoDevices = all.filter(d => d.kind === "videoinput");
    // ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ index ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á (label ‡∏°‡∏µ back/rear/environment)
    const backIdx = videoDevices.findIndex(d => /back|rear|environment/i.test(d.label));
    if (backIdx >= 0) currentIndex = backIdx;
    else currentIndex = 0; // ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ first camera
  }

  async function startCamera() {
    try {
      if (firstRun) {
        await enumerateVideoDevices();
        await loadModel();
        firstRun = false;
      }
      await openWebcam();
    } catch (e) {
      alert("Error starting camera: " + e.message);
    }
  }

  async function openWebcam() {
    // ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏° ‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà ‡πÉ‡∏´‡πâ‡∏õ‡∏¥‡∏î‡∏Å‡πà‡∏≠‡∏ô
    if (webcam?.webcam?.srcObject) {
      webcam.webcam.srcObject.getTracks().forEach(t => t.stop());
      await webcam.stop();
    }

    const device = videoDevices[currentIndex];
    if (!device) throw new Error("No video devices found");
    const constraints = { video: { deviceId: { exact: device.deviceId } }, audio: false };

    webcam = new tmImage.Webcam(300, 300, true);
    await webcam.setup(constraints);
    await webcam.play();
    window.requestAnimationFrame(loop);

    // render
    const wc = document.getElementById("webcam-container");
    wc.innerHTML = "";
    wc.appendChild(webcam.canvas);

    const lc = document.getElementById("label-container");
    lc.innerHTML = "";
    for (let i = 0; i < maxPredictions; i++) lc.appendChild(document.createElement("div"));
  }

  async function loop() {
    webcam.update();
    const predictions = await model.predict(webcam.canvas);
    predictions.forEach((p, i) => {
      document.getElementById("label-container").childNodes[i].innerText =
        `${p.className}: ${(p.probability * 100).toFixed(2)}%`;
    });
    window.requestAnimationFrame(loop);
  }

  function toggleCamera() {
    if (!videoDevices.length) return;
    currentIndex = (currentIndex + 1) % videoDevices.length;
    openWebcam().catch(e => alert("Cannot switch camera: " + e.message));
  }
</script>
</body>
</html>
