<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Teachable Machine Image Model</title>
  <!-- ‡∏ï‡∏≤‡∏¢‡∏ï‡∏±‡∏ß ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏°‡∏µ tmImage -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8.4/dist/teachablemachine-image.min.js"></script>
  <style>
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body { font-family: sans-serif; text-align: center; padding: 10px; }
    h1 { font-size: 1.5rem; margin-bottom: 10px; }
    #controls { display: flex; justify-content: center; gap: 10px; flex-wrap: wrap; margin-bottom: 10px; }
    button {
      flex: 1 1 40%;
      padding: 12px;
      font-size: 1rem;
      border: none;
      border-radius: 6px;
      background-color: #007bff;
      color: white;
    }
    #webcam-container {
      width: 100%;
      max-width: 100vw;
      overflow: hidden;
      display: flex;
      justify-content: center;
      margin-bottom: 10px;
    }
    video {
      width: 100%;
      height: auto;
      max-width: 100%;
      border-radius: 12px;
    }
    #label-container {
      width: 100%;
      max-width: 100%;
      margin-top: 10px;
    }
    #label-container > div {
      font-size: 1rem;
      margin: 4px 0;
      background: rgba(0, 0, 0, 0.05);
      padding: 6px;
      border-radius: 4px;
    }
  </style>
</head>
<body>
  <h1>Teachable Machine Image Model</h1>
  <div id="controls">
    <button id="start-btn">‚ñ∂Ô∏èStart</button>
    <button id="switch-btn">üîÑSwitch Camera</button>
  </div>
  <div id="webcam-container">
    <video id="webcam" autoplay playsinline></video>
  </div>
  <div id="label-container"></div>

<script>
  const MODEL_PATH = "./tm-my-image-model/";
  let model, maxPredictions, stream;
  let currentFacing = "environment";

  async function loadModel() {
    if (!model) {
      model = await tmImage.load(
        MODEL_PATH + "model.json",
        MODEL_PATH + "metadata.json"
      );
      maxPredictions = model.getTotalClasses();
    }
  }

  async function startVideo() {
    try {
      if (stream) {
        stream.getTracks().forEach(t => t.stop());
      }
      let constraints = {
        video: { facingMode: { exact: currentFacing }, width: { ideal: 640 }, height: { ideal: 480 } },
        audio: false
      };
      try {
        stream = await navigator.mediaDevices.getUserMedia(constraints);
      } catch {
        constraints.video.facingMode = currentFacing;
        stream = await navigator.mediaDevices.getUserMedia(constraints);
      }
      const video = document.getElementById("webcam");
      video.srcObject = stream;
      await new Promise(resolve => video.onloadedmetadata = resolve);
    } catch (e) {
      alert("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á: " + e.message);
      console.error(e);
    }
  }

  async function init() {
    await loadModel();
    await startVideo();
    requestAnimationFrame(loop);
  }

  async function loop() {
    const video = document.getElementById("webcam");
    const predictions = await model.predict(video);
    const container = document.getElementById("label-container");
    container.innerHTML = "";
    predictions.forEach(p => {
      const div = document.createElement("div");
      div.innerText = `${p.className}: ${(p.probability * 100).toFixed(2)}%`;
      container.appendChild(div);
    });
    requestAnimationFrame(loop);
  }

  async function switchCamera() {
    currentFacing = currentFacing === "environment" ? "user" : "environment";
    await startVideo();
  }

  document.getElementById("start-btn").onclick = init;
  document.getElementById("switch-btn").onclick = switchCamera;
</script>
</body>
</html>
